---
title: "2022 Monitoring Plan"
author: "Emma Jones"
date: "6/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# built in R 3.6.2
library(tidyverse)
library(sf)
library(config)
library(DBI)
library(pool)
library(dbplyr)
library(leaflet)
library(inlmisc)
library(DT)
library(lubridate)
library(readxl)
library(pins)

# Get configuration settings
conn <- config::get("connectionSettings")

board_register_rsconnect(key = conn$CONNECT_API_KEY,  #Sys.getenv("CONNECT_API_KEY"),
                         server = conn$CONNECT_SERVER)#Sys.getenv("CONNECT_SERVER"))

## Connect to ODS production
pool <- dbPool(
  drv = odbc::odbc(),
  Driver = "ODBC Driver 11 for SQL Server",#Driver = "SQL Server Native Client 11.0",
  Server= "DEQ-SQLODS-PROD,50000",
  dbname = "ODS",
  trusted_connection = "yes"
)
```

## Project Background

BRRO's monitoring planning process is being updated to a more reproducible and efficient collaborative process that utilizes modern project sharing techniques. This report serves as one project archive to aid in future monitoring plan development.

The general steps of a monitoring plan development involve identifying where previous plans have sampled and what frequency, comparing that information with longer term sampling goals, and identifying stations to be monitored in the upcoming year. After the plan is mapped out for the forthcoming season, new stations are created (as needed) in CEDS, monitoring staff build runs to efficiently collect samples and program these runs in CEDS. After a region is done with their monitoring plan, Central Office staff review the plan to ensure statewide goals and budget are met, providing feedback for the region if needed.

### Data Gathering

First, we will bring in the 2022 IR dataset to get a longer term view of sampling efforts in BRRO. This dataset encompasses 2015-2020. The station project codes and sample frequency are useful to the planning process to ensure sampling goals have been met. 

After this data is summarized, we will pull the 2021 sample information (to date) from CEDS to run through a similar process. 

By mapping this information we can quickly identify areas that might be lacking data for upcoming assessment windows and correct for potential data gaps.

```{r bring in precompiled spatial data}
WQM_Stations_Spatial <- pin_get("ejones/WQM-Stations-Spatial", board = "rsconnect") %>%
  rename("Basin_Name" = "Basin_Code")   # can't have same name different case when using sqldf
WQM_Stations_Spatial_BRRO <-  filter(WQM_Stations_Spatial, ASSESS_REG == 'BRRO')
```


```{r conventionals IR2022}
# Takes a while so only do this once and save BRRO subset locally
# conventionals <- read_excel('C:/HardDriveBackup/R/GitHub/IR2022/2.organizeMetadata/data/final2022data/CEDSWQM/CONVENTIONALS_20210504.xlsx') %>%
#   # get it in real conventionals format
#   rename('Deq_Region'='VADEQ_ADMIN_REGION', 'STA_REC_CODE' = 'MONITORING_REGION',
#          'ECOLI' = 'E.COLI_ECOLI_CFU/100mL', 'ENTEROCOCCI' = 'ENTEROCOCCI_31649_NO/100mL')  %>%
#   ## filter to just BRRO, very broad here using station retrieve code and region code
#   #filter(STA_REC_CODE == 'BRRO' | Deq_Region == 'Blue Ridge')
#   left_join(WQM_Stations_Spatial, by = c("FDT_STA_ID" = 'StationID')) %>% 
#   filter(ASSESS_REG == 'BRRO')
# saveRDS(conventionals, 'data/IR2022conventionalsBRRO.RDS')
conventionals <- readRDS('data/IR2022conventionalsBRRO.RDS')  

```


Now pull sample info for 2021 sample data from CEDS.

```{r 2021 sample data from CEDS}
sampleWindow <- c(as.Date('2021-01-01'), as.Date(Sys.Date()))
windowInfo <- pool %>% tbl( in_schema("wqm", "Wqm_Field_Data_View")) %>%
  filter(Fdt_Sta_Id %in% !! WQM_Stations_Spatial_BRRO$StationID &
           between(as.Date(Fdt_Date_Time), !! sampleWindow[1], !! sampleWindow[2])) %>%
  as_tibble() 

```


Now we can combine these datasets and summarize sample information

```{r combine data and summarize}

windowSampleInfo <- conventionals %>% 
  dplyr::select(FDT_STA_ID, FDT_SPG_CODE, FDT_DATE_TIME ) %>% 
  bind_rows(
    dplyr::select(windowInfo, FDT_STA_ID = Fdt_Sta_Id, FDT_SPG_CODE = Fdt_Spg_Code, FDT_DATE_TIME = Fdt_Date_Time)) %>% 
  mutate(Year = year(FDT_DATE_TIME)) %>% #paste0(year(FDT_DATE_TIME)), ' Sample n') %>% 
  group_by(FDT_STA_ID, Year) %>% 
  summarise(`Sample n` = n(),
            `SPG codes` = paste(unique(FDT_SPG_CODE),  collapse = ' | '),
            `SPG codes First` = as.factor(unique(FDT_SPG_CODE)[1])) %>% # keep this first one for mapping purposes
  mutate(IR2022 = case_when(Year %in% c(2015:2020) ~ 'IR 2022',
                                       TRUE ~ as.character(NA)),
         IR2024 = case_when(Year %in% c(2017:2022) ~ 'IR 2024',
                                       TRUE ~ as.character(NA)),
         IR2026 = case_when(Year %in% c(2019:2024) ~ 'IR 2026',
                                       TRUE ~ as.character(NA))) %>% 
  group_by(FDT_STA_ID, IR2022 ) %>% 
  mutate(`IR2022 Sample n` = case_when(IR2022 == 'IR 2022' ~ sum(`Sample n`))) %>% 
   ungroup() %>% group_by(FDT_STA_ID, IR2024 ) %>% 
  mutate(`IR2024 Sample n` = case_when(IR2024 == 'IR 2024' ~ sum(`Sample n`))) %>% 
  ungroup() %>%  group_by(FDT_STA_ID, IR2026 ) %>% 
  mutate(`IR2026 Sample n` = case_when(IR2026 == 'IR 2026' ~ sum(`Sample n`))) %>% 
  ungroup() %>% dplyr::select(-c(IR2022, IR2024, IR2026)) 

windowSampleInfoSummary <- dplyr::select(windowSampleInfo, -c(`IR2022 Sample n`, `IR2024 Sample n`, `IR2026 Sample n`)) %>% 
  group_by(FDT_STA_ID) %>% 
  pivot_wider(names_from = 'Year', names_prefix = "Year", values_from = c('Sample n', 'SPG codes', 'SPG codes First')) 


#old skool rename of columns
names(windowSampleInfoSummary)[2:length(names(windowSampleInfoSummary))] <-
  paste(strsplit(names(windowSampleInfoSummary)[2:length(names(windowSampleInfoSummary))], '_') %>% 
         map_chr(2),
       strsplit(names(windowSampleInfoSummary)[2:length(names(windowSampleInfoSummary))], '_') %>% 
         map_chr(1), sep = ' ')

# rearrange column order to make sense
windowSampleInfoFinalSummary <- windowSampleInfoSummary %>% 
  select(sort(tidyselect::peek_vars())) %>% 
  left_join(dplyr::select(windowSampleInfo, FDT_STA_ID, `IR2022 Sample n`, `IR2024 Sample n`, `IR2026 Sample n`) %>% 
              pivot_longer(cols = c(`IR2022 Sample n`, `IR2024 Sample n`, `IR2026 Sample n`), names_to = 'window', values_to = 'value') %>% 
              group_by(FDT_STA_ID, window) %>%
              filter(value > 0) %>% ungroup() %>% 
              group_by(FDT_STA_ID, window) %>% 
              mutate(n = 1:n()) %>% 
              filter(n == 1) %>% dplyr::select(-n) %>% 
              pivot_wider(names_from = 'window', values_from = 'value'), by = 'FDT_STA_ID') %>% 
  left_join(dplyr::select(WQM_Stations_Spatial, StationID:Sta_Desc, ASSESS_REG, VAHU6), by = c('FDT_STA_ID' = 'StationID')) %>% 
  dplyr::select( FDT_STA_ID, Sta_Desc, ASSESS_REG, VAHU6, `IR2022 Sample n`, `IR2024 Sample n`,  `IR2026 Sample n`, everything()) %>% 
  st_as_sf(coords = c("Longitude", "Latitude"),  # make spatial layer using these columns
           remove = T, # don't remove these lat/lon cols from df
           crs = 4326)
rm(conventionals);rm(windowInfo); rm(windowSampleInfo);rm(windowSampleInfoSummary)
```


### Process data gaps from summary information

Next we need to identify VAHU6s that don't have adequate sample information for upcoming IR windows.

```{r ir window summary}
assessmentRegionsVAHU6 <- st_read( 'data/GIS/AssessmentRegions_VA84_basins.shp') %>% 
 filter(ASSESS_REG == 'BRRO') %>% 
  dplyr::select(VAHU6, ASSESS_REG)

ir2022 <- left_join(assessmentRegionsVAHU6, 
                    windowSampleInfoFinalSummary %>% 
                      filter(!is.na(`IR2022 Sample n`)) %>% 
                      group_by(VAHU6) %>% 
                      summarise(`n Stations` = length(unique(FDT_STA_ID))) %>% 
                      left_join(
                        windowSampleInfoFinalSummary %>% 
                          group_by(VAHU6) %>% 
                          summarise(`n Samples` = sum(`IR2022 Sample n`, na.rm = T)) , by = 'VAHU6'  ) ,
                    by = 'VAHU6') %>% 
  mutate(IR2022 = as.factor(case_when(is.na(`n Stations`) ~ 'Need Station', 
                            between(`n Samples`, 1, 9) ~ '< 10 samples',
                            `n Samples` >9 ~ 'Fine')))
#View(ir2022 %>% st_drop_geometry())


ir2024 <- left_join(assessmentRegionsVAHU6, 
                    windowSampleInfoFinalSummary %>% 
                      filter(!is.na(`IR2024 Sample n`)) %>% 
                      group_by(VAHU6) %>% 
                      summarise(`n Stations` = length(unique(FDT_STA_ID))) %>% 
                      left_join(
                        windowSampleInfoFinalSummary %>% 
                          group_by(VAHU6) %>% 
                          summarise(`n Samples` = sum(`IR2024 Sample n`, na.rm = T)) , by = 'VAHU6'  ),
                     by = 'VAHU6') %>% 
  mutate(IR2024 = as.factor(case_when(is.na(`n Stations`) ~ 'Need Station', 
                            between(`n Samples`, 1, 9) ~ '< 10 samples',
                            `n Samples` >9 ~ 'Fine')))

ir2026 <- left_join(assessmentRegionsVAHU6, 
                    windowSampleInfoFinalSummary %>% 
                      filter(!is.na(`IR2026 Sample n`)) %>% 
                      group_by(VAHU6) %>% 
                      summarise(`n Stations` = length(unique(FDT_STA_ID))) %>% 
                      left_join(
                        windowSampleInfoFinalSummary %>% 
                          group_by(VAHU6) %>% 
                          summarise(`n Samples` = sum(`IR2026 Sample n`, na.rm = T)) , by = 'VAHU6'  ) ,
                    by = 'VAHU6') %>% 
  mutate(IR2026 = as.factor(case_when(is.na(`n Stations`) ~ 'Need Station', 
                            between(`n Samples`, 1, 9) ~ '< 10 samples',
                            `n Samples` >9 ~ 'Fine')))
#View(ir2026 %>% st_drop_geometry())
```

### Process stations into annual layers

```{r stations to annual layers}
# make individual layers and unique identifiers so the layerID's work
x2015 <- windowSampleInfoFinalSummary %>% ungroup() %>% 
  filter( !is.na(`Year2015 Sample n`)) %>% st_as_sf() %>% 
  mutate(UID = paste0(FDT_STA_ID,'/2015'))
x2016 <- windowSampleInfoFinalSummary %>% ungroup() %>% 
  filter( !is.na(`Year2016 Sample n`)) %>% st_as_sf() %>% 
  mutate(UID = paste0(FDT_STA_ID,'/2016'))
x2017 <- windowSampleInfoFinalSummary %>% ungroup() %>% 
  filter( !is.na(`Year2017 Sample n`)) %>% st_as_sf() %>% 
  mutate(UID = paste0(FDT_STA_ID,'/2017'))
x2018 <- windowSampleInfoFinalSummary %>% ungroup() %>% 
  filter( !is.na(`Year2018 Sample n`)) %>% st_as_sf() %>% 
  mutate(UID = paste0(FDT_STA_ID,'/2018'))
x2019 <- windowSampleInfoFinalSummary %>% ungroup() %>% 
  filter( !is.na(`Year2019 Sample n`)) %>% st_as_sf() %>% 
  mutate(UID = paste0(FDT_STA_ID,'/2019'))
x2020 <- windowSampleInfoFinalSummary %>% ungroup() %>% 
  filter( !is.na(`Year2020 Sample n`)) %>% st_as_sf() %>% 
  mutate(UID = paste0(FDT_STA_ID,'/2020'))
x2021 <- windowSampleInfoFinalSummary %>% ungroup() %>% 
  filter( !is.na(`Year2021 Sample n`)) %>% st_as_sf() %>% 
  mutate(UID = paste0(FDT_STA_ID,'/2021'))

# save data for app
saveRDS(windowSampleInfoFinalSummary,'data/processedData/AllStations.RDS')
saveRDS(x2015, 'data/processedData/stations2015.RDS')
saveRDS(x2016, 'data/processedData/stations2016.RDS')
saveRDS(x2017, 'data/processedData/stations2017.RDS')
saveRDS(x2018, 'data/processedData/stations2018.RDS')
saveRDS(x2019, 'data/processedData/stations2019.RDS')
saveRDS(x2020, 'data/processedData/stations2020.RDS')
saveRDS(x2021, 'data/processedData/stations2021.RDS')
saveRDS(ir2022, 'data/processedData/vahu62022.RDS')
saveRDS(ir2024, 'data/processedData/vahu62024.RDS')
saveRDS(ir2026, 'data/processedData/vahu62026.RDS')
```


### Visualize summary information

```{r map}
assessmentRegions <- st_read( 'data/GIS/AssessmentRegions_simple.shp')


pal <- colorFactor(
      palette = rainbow(7),
      domain = assessmentRegions$ASSESS_REG)

pal2 <- colorFactor(
      palette = c('yellow', 'green','red'),
      domain = levels(ir2022$IR2022))

                            
stationPal <- colorFactor(palette = rainbow(11),
                          domain = unique(windowSampleInfoFinalSummary %>% 
                              dplyr::select(contains('SPG codes First')) %>% 
                              pivot_longer(cols = contains('SPG codes First'), names_to = 'year', values_to = 'SPG') %>% 
                              filter(!is.na(SPG)) %>% 
                              distinct(SPG) %>% 
                              pull(SPG)))

CreateWebMap(maps = c("Topo","Imagery","Hydrography"), collapsed = TRUE,
             options= leafletOptions(zoomControl = TRUE,minZoom = 3, maxZoom = 20,
                                     preferCanvas = TRUE)) %>%
  setView(-79.1, 37.7, zoom=7)  %>%
  # addPolygons(data= assessmentRegions,  color = 'black', weight = 1,
  #             fillColor= ~pal(assessmentRegions$ASSESS_REG), fillOpacity = 0.5,stroke=0.1,
  #             group="Assessment Regions", label = ~ASSESS_REG) %>% hideGroup('Assessment Regions') %>%
  # addPolygons(data= assessmentRegionsVAHU6,  color = 'black', weight = 1,
  #             fillColor= 'gray', fillOpacity = 0.5,stroke=0.1,
  #             group="BRRO VAHU6's", label = ~VAHU6) %>% hideGroup("BRRO VAHU6's") %>%
  # addPolygons(data= ir2022,  color = 'black', weight = 1,
  #             fillColor= ~pal2(ir2022$IR2022), fillOpacity = 0.5,stroke=0.1,
  #             group="IR2022 VAHU6's", label = ~VAHU6,
  #             popup = leafpop::popupTable(ir2022, zcol=c('VAHU6', 'n Stations', 'n Samples', 'IR2022'))) %>% hideGroup("IR2022 VAHU6's") %>%
  # addPolygons(data= ir2024,  color = 'black', weight = 1,
  #             fillColor= ~pal2(ir2024$IR2024), fillOpacity = 0.5,stroke=0.1,
  #             group="IR2024 VAHU6's", label = ~VAHU6,
  #             popup = leafpop::popupTable(ir2024, zcol=c('VAHU6', 'n Stations', 'n Samples', 'IR2024'))) %>% hideGroup("IR2024 VAHU6's") %>%
  addPolygons(data= ir2026,  color = 'black', weight = 1,
              fillColor= ~pal2(ir2026$IR2026), fillOpacity = 0.5,stroke=0.1,
              group="IR2026 VAHU6's", label = ~VAHU6,
              popup = leafpop::popupTable(ir2026, zcol=c('VAHU6', 'n Stations', 'n Samples', 'IR2026'))) %>% hideGroup("IR2026 VAHU6's") %>%
  
  addCircleMarkers(data = x2015, color='black', fillColor=~stationPal(`Year2015 SPG codes First`), #'gray', 
                   radius = 4, fillOpacity = 0.5,opacity=0.8,weight = 2,stroke=T, group="2015 Stations",
                       label = ~FDT_STA_ID, layerId = ~UID,
                       popup = leafpop::popupTable(x2015, zcol=c('FDT_STA_ID', 'Sta_Desc', 'VAHU6', 
                                                                 'Year2015 Sample n', 'Year2015 SPG codes'))) %>% hideGroup('2015 Stations') %>%
    addCircleMarkers(data = x2016, color='black', fillColor=~stationPal(`Year2016 SPG codes First`), #color='blue', fillColor='gray', 
                     radius = 4, fillOpacity = 0.5,opacity=0.8,weight = 2,stroke=T, group="2016 Stations",
                       label = ~FDT_STA_ID, layerId = ~UID,
                       popup = leafpop::popupTable(x2016, zcol=c('FDT_STA_ID', 'Sta_Desc', 'VAHU6',
                                                                 'Year2016 Sample n', 'Year2016 SPG codes'))) %>% hideGroup('2016 Stations') %>%
    addCircleMarkers(data = x2017,  color='black', fillColor=~stationPal(`Year2017 SPG codes First`), #color='blue', fillColor='gray', 
                     radius = 4, fillOpacity = 0.5,opacity=0.8,weight = 2,stroke=T, group="2017 Stations",
                       label = ~FDT_STA_ID, layerId = ~UID,
                       popup = leafpop::popupTable(x2017, zcol=c('FDT_STA_ID', 'Sta_Desc', 'VAHU6',
                                                                 'Year2017 Sample n', 'Year2017 SPG codes'))) %>% hideGroup('2017 Stations') %>%
    addCircleMarkers(data = x2018,  color='black', fillColor=~stationPal(`Year2018 SPG codes First`), #color='blue', fillColor='gray', 
                     radius = 4, fillOpacity = 0.5,opacity=0.8,weight = 2,stroke=T, group="2018 Stations",
                       label = ~FDT_STA_ID, layerId = ~UID,
                       popup = leafpop::popupTable(x2018, zcol=c('FDT_STA_ID', 'Sta_Desc', 'VAHU6',
                                                                 'Year2018 Sample n', 'Year2018 SPG codes'))) %>% hideGroup('2018 Stations') %>%
    addCircleMarkers(data = x2019, color='black', fillColor=~stationPal(`Year2019 SPG codes First`), #color='blue', fillColor='gray',  
                     radius = 4, fillOpacity = 0.5,opacity=0.8,weight = 2,stroke=T, group="2019 Stations",
                       label = ~FDT_STA_ID, layerId = ~UID,
                       popup = leafpop::popupTable(x2019, zcol=c('FDT_STA_ID', 'Sta_Desc', 'VAHU6',
                                                                 'Year2019 Sample n', 'Year2019 SPG codes'))) %>% hideGroup('2019 Stations') %>%
    addCircleMarkers(data = x2020,  color='black', fillColor=~stationPal(`Year2020 SPG codes First`), #color='blue', fillColor='gray',  
                     radius = 4, fillOpacity = 0.5,opacity=0.8,weight = 2,stroke=T, group="2020 Stations",
                       label = ~FDT_STA_ID, layerId = ~UID,
                       popup = leafpop::popupTable(x2020, zcol=c('FDT_STA_ID', 'Sta_Desc', 'VAHU6',
                                                                 'Year2020 Sample n', 'Year2020 SPG codes'))) %>% hideGroup('2020 Stations') %>%
    addCircleMarkers(data = x2021,  color='black', fillColor=~stationPal(`Year2021 SPG codes First`), #color='blue', fillColor='gray', 
                     radius = 4, fillOpacity = 0.5,opacity=0.8,weight = 2,stroke=T, group="2021 Stations",
                       label = ~FDT_STA_ID, layerId = ~UID,
                       popup = leafpop::popupTable(x2021, zcol=c('FDT_STA_ID', 'Sta_Desc', 'VAHU6',
                                                                 'Year2021 Sample n', 'Year2021 SPG codes'))) %>% hideGroup('2021 Stations') %>%
  addCircleMarkers(data = windowSampleInfoFinalSummary %>% st_as_sf(), color='blue', fillColor='gray', radius = 4,
                       fillOpacity = 0.5,opacity=0.8,weight = 2,stroke=T, group="All Stations",
                       label = ~FDT_STA_ID, layerId = ~FDT_STA_ID,
                       popup = leafpop::popupTable(windowSampleInfoFinalSummary, zcol=c('FDT_STA_ID', 'Sta_Desc', 'VAHU6',
                                                                 'IR2022 Sample n', 'IR2024 Sample n', 'IR2026 Sample n'))) %>% hideGroup('All Stations') %>%
  addLegend(data = x2015,'topright', pal = stationPal, values = ~`Year2015 SPG codes First`, title = 'Individual Year SPG Codes') %>% 
  inlmisc::AddSearchButton(group = 'All Stations', zoom = 15, textPlaceholder = "Search by StationID") %>% 
  inlmisc::AddHomeButton(raster::extent(-83.89, -74.80, 36.54, 39.98), position = "topleft") %>%
  addLayersControl(baseGroups=c("Topo","Imagery","Hydrography"),
                   overlayGroups = c("Assessment Regions", "BRRO VAHU6's","IR2022 VAHU6's", "IR2024 VAHU6's",  "IR2026 VAHU6's",
                                     'All Stations', "2015 Stations","2016 Stations","2017 Stations","2018 Stations",
                                     "2019 Stations","2020 Stations", "2021 Stations"),
                                     #"IR2022 Missing VAHU6's", "IR2024 Missing VAHU6's"),
                   options=layersControlOptions(collapsed=T),
                   position='topleft')     


```

## Next steps

So now we have the fundamental data necessary for building an application for monitoring plan development. The application will display this map (2021 data will be pulled fresh upon app upload since we are in the middle of the sample season) and allow users to upload a list of stations in an xlsx.  That uploaded dataset can contain any number of sheets, additional data; the app will look for a specific column named StationID and will join those unique sites to WQM_Stations_Spatial (rebuilt weekly) to plot proposed monitoring network on this map to plug any upcoming data holes. The application will also update the IR2024 and IR2026 VAHU6 layers to reflect flags where VAHU6s don't have stations. Links to the GIS staff app will be provided to assist the identification of existing stations that could be added to the monitoring plan.

Additional features will be added per user request.


### Test reanalyze VAHU6 needs with uploaded dataset

```{r user upload}
# use same layers as weekly pin (where WQM_Stations_Spatial comes from)
vahu6 <- st_read('data/GIS/VA_SUBWATERSHED_6TH_ORDER_STG.shp') # this version of vahu6 layer goes outside state boundary
subbasinConversion <- read_csv('data/subbasinToVAHU6conversion.csv')
unrestrictedAssessmentRegionVAHU6Subbasin <- left_join(vahu6, subbasinConversion, by = c('VAHU6', 'VAHU5'))


# make sure uploaded dataset has correct sheet names
if('Sample Plan' %in% excel_sheets('uploadData/Draft  MonPlan 2021-2022EVJ.xlsx')){
  userUpload <- read_excel('uploadData/Draft  MonPlan 2021-2022EVJ.xlsx', sheet = 'Sample Plan') }
stationRaw <- dplyr::select(userUpload, StationID, lat = Latitude, lng = Longitude) %>% # make new lat/lng fields in case user info here
  filter(!is.na(StationID)) %>%  # drop extra excel rows 
  left_join(WQM_Stations_Spatial, by = 'StationID')
if(nrow(filter(stationRaw, is.na(Latitude) | is.na(Longitude))) > 0 ){
  # Get spatial info for new stations
  fix <- filter(stationRaw, is.na(Latitude) | is.na(Longitude)) %>% 
    st_as_sf(coords = c("lng", "lat"),  # make spatial layer using these columns
           remove = F, # don't remove these lat/lon cols from df
           crs = 4326) %>% 
    st_intersection(dplyr::select(unrestrictedAssessmentRegionVAHU6Subbasin, ASSESS_REG, VAHU6)) %>% 
    mutate(ASSESS_REG = ASSESS_REG.1,
           VAHU6 = VAHU6.1,
           Latitude = lat,
           Longitude = lng) %>% 
    dplyr::select(-c(ASSESS_REG.1, VAHU6.1, lat,lng))
  stationPlan <- bind_rows(
    filter(stationRaw, !StationID %in% fix$StationID),
    fix %>% st_drop_geometry()) 
} else {
  stationPlan <- stationRaw
}

# add proposed sampling frequency to window info
windowInfoNew <- fakeDataFunction(stationPlan, userUpload, windowInfo)

# reanalyze monitoring network by vahu6
newMonitoring <- vahu6Layout(conventionals, windowInfoNew, WQM_Stations_Spatial, stationPlan) %>% ungroup() %>% st_as_sf()

```




Functions to make it all happen. These need to be updated as IR2020 drops off and IR2026+ needed for planning. 

```{r create fake data}
# function to create fake data based on user input
fakeDataFunction <- function(stationPlan, userUpload, windowInfo){
  zz <- left_join(dplyr::select(stationPlan, StationID),  
                dplyr::select(userUpload, `Monitoring Year`, StationID, `Station Type`,`Annual Frequency`), 
                by = 'StationID')
  dataOut <- windowInfo
  for(i in 1:nrow(zz)){
    dataOut <- bind_rows(dataOut,
                         tibble(Fdt_Sta_Id = zz[i,]$StationID, Fdt_Date_Time = as.Date(paste0(zz[i,]$`Monitoring Year`, '-01-01 12:01:01')),
                                Fdt_Spg_Code = zz[i,]$`Station Type`, fakeData = 1:zz[i,]$`Annual Frequency`))  }
  return(dataOut)
}

```

```{r function to reanalyze data}
vahu6Layout <- function(conventionals, # most recent conventionals dataset
                        windowInfo, # extra data needed not covered in conventionals dataset
                        WQM_Stations_Spatial,
                        stationPlan ){
  windowSampleInfo <- conventionals %>% 
    dplyr::select(FDT_STA_ID, FDT_SPG_CODE, FDT_DATE_TIME ) %>% 
  bind_rows(
    dplyr::select(windowInfo, FDT_STA_ID = Fdt_Sta_Id, FDT_SPG_CODE = Fdt_Spg_Code, FDT_DATE_TIME = Fdt_Date_Time)) %>% 
  mutate(Year = year(FDT_DATE_TIME)) %>% #paste0(year(FDT_DATE_TIME)), ' Sample n') %>% 
  group_by(FDT_STA_ID, Year) %>% 
  summarise(`Sample n` = n(),
            `SPG codes` = paste(unique(FDT_SPG_CODE),  collapse = ' | '),
            `SPG codes First` = as.factor(unique(FDT_SPG_CODE)[1])) %>% # keep this first one for mapping purposes
  mutate(IR2022 = case_when(Year %in% c(2015:2020) ~ 'IR 2022',
                                       TRUE ~ as.character(NA)),
         IR2024 = case_when(Year %in% c(2017:2022) ~ 'IR 2024',
                                       TRUE ~ as.character(NA)),
         IR2026 = case_when(Year %in% c(2019:2024) ~ 'IR 2026',
                                       TRUE ~ as.character(NA))) %>% 
  group_by(FDT_STA_ID, IR2022 ) %>% 
  mutate(`IR2022 Sample n` = case_when(IR2022 == 'IR 2022' ~ sum(`Sample n`))) %>% 
   ungroup() %>% group_by(FDT_STA_ID, IR2024 ) %>% 
  mutate(`IR2024 Sample n` = case_when(IR2024 == 'IR 2024' ~ sum(`Sample n`))) %>% 
  ungroup() %>%  group_by(FDT_STA_ID, IR2026 ) %>% 
  mutate(`IR2026 Sample n` = case_when(IR2026 == 'IR 2026' ~ sum(`Sample n`))) %>% 
  ungroup() %>% dplyr::select(-c(IR2022, IR2024, IR2026)) 

windowSampleInfoSummary <- dplyr::select(windowSampleInfo, -c(`IR2022 Sample n`, `IR2024 Sample n`, `IR2026 Sample n`)) %>% 
  group_by(FDT_STA_ID) %>% 
  pivot_wider(names_from = 'Year', names_prefix = "Year", values_from = c('Sample n', 'SPG codes', 'SPG codes First')) 


#old skool rename of columns
names(windowSampleInfoSummary)[2:length(names(windowSampleInfoSummary))] <-
  paste(strsplit(names(windowSampleInfoSummary)[2:length(names(windowSampleInfoSummary))], '_') %>% 
         map_chr(2),
       strsplit(names(windowSampleInfoSummary)[2:length(names(windowSampleInfoSummary))], '_') %>% 
         map_chr(1), sep = ' ')

WQM_Stations_Spatial_New <- bind_rows(WQM_Stations_Spatial, stationPlan) %>% distinct(StationID, .keep_all = T)

# rearrange column order to make sense
windowSampleInfoFinalSummary <- windowSampleInfoSummary %>% 
  select(sort(tidyselect::peek_vars())) %>% 
  left_join(dplyr::select(windowSampleInfo, FDT_STA_ID, `IR2022 Sample n`, `IR2024 Sample n`, `IR2026 Sample n`) %>% 
              pivot_longer(cols = c(`IR2022 Sample n`, `IR2024 Sample n`, `IR2026 Sample n`), names_to = 'window', values_to = 'value') %>% 
              group_by(FDT_STA_ID, window) %>%
              filter(value > 0) %>% ungroup() %>% 
              group_by(FDT_STA_ID, window) %>% 
              mutate(n = 1:n()) %>% 
              filter(n == 1) %>% dplyr::select(-n) %>% 
              pivot_wider(names_from = 'window', values_from = 'value'), by = 'FDT_STA_ID') %>% 
  left_join(dplyr::select(WQM_Stations_Spatial_New, StationID:Sta_Desc, ASSESS_REG, VAHU6), by = c('FDT_STA_ID' = 'StationID')) %>% 
  dplyr::select( FDT_STA_ID, Sta_Desc, ASSESS_REG, VAHU6, `IR2022 Sample n`, `IR2024 Sample n`,  `IR2026 Sample n`, everything()) %>% 
  st_as_sf(coords = c("Longitude", "Latitude"),  # make spatial layer using these columns
           remove = T, # don't remove these lat/lon cols from df
           crs = 4326)
return(windowSampleInfoFinalSummary)}
```

